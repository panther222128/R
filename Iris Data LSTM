install.packages("keras")
install.packages("dplyr")
install.packages("igraph")

library(keras)
library(dplyr)
library(igraph)

data(iris)

iris

plot(iris$Petal.Width, col = iris$Species)

onehot.species = to_categorical(as.numeric(iris$Species)-1)

iris = as.matrix(iris[, 1:4])
iris = cbind(iris, onehot.species)

head(iris)

set.seed(17)
ind <- sample(2, nrow(iris), replace = TRUE, prob = c(0.7, 0.3))

iris.training <- iris[ind == 1, 1:4]
iris.test <- iris[ind == 2, 1:4]
iris.trainingtarget <- iris[ind == 1, -seq(4)]
iris.testtarget <- iris[ind == 2, -(1:4)]

iris.training
iris.test
iris.trainingtarget
iris.testtarget

model <- keras_model_sequential()

model %>% layer_dense(units = ncol(iris.trainingtarget), activation = 'softmax', input_shape = ncol(iris.training))

summary(model)

model$inputs

model$outputs



g = graph_from_literal(Sepal.Length:Sepal.Width:Petal.Length:Petal.Width---Species,simplify = TRUE)

layout <- layout_in_circle(g, order = order(degree(g)))

plot(g,layout = layout, vertex.color = c(2,2,2,2,3))



sgd <- optimizer_sgd(lr = 0.01)

model %>% compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = 'accuracy')

history <- model %>% fit(x = iris.training, y = iris.trainingtarget, epochs = 100, batch_size = 5, validation_split = 0.2, verbose = TRUE)

plot(history)

classes <- model %>% predict_classes(iris.test)

table(iris.testtarget%*%0:2, classes)

score <- model %>% evaluate(iris.test, iris.testtarget)

                            
